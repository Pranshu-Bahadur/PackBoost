{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Pranshu-Bahadur/PackBoost/blob/main/notebooks/numerai_gpu_demo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PackBoost Numerai Demo\n",
    "\n",
    "This notebook downloads a slice of the Numerai dataset, bins features, and\n",
    "trains PackBoost on CPU and (optionally) GPU. It is designed for Google\n",
    "Colab \u2013 adjust the installation cell if you prefer a local environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Install dependencies (edit REPO_URL if you forked the project)\n",
    "REPO_URL = \"https://github.com/Pranshu-Bahadur/PackBoost.git\"  # TODO: update if needed\n",
    "FORCE_CPU_BACKEND = False  # Set True to skip CUDA build (uses PACKBOOST_DISABLE_CUDA)\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "cuda_bin = Path('/usr/local/cuda/bin')\n",
    "if cuda_bin.exists() and str(cuda_bin) not in os.environ['PATH']:\n",
    "    os.environ['PATH'] = os.environ['PATH'] + os.pathsep + str(cuda_bin)\n",
    "!pip install -q numerapi pandas~=2.2 pyarrow~=15.0\n",
    "!pip install -q catboost lightgbm xgboost\n",
    "\n",
    "if FORCE_CPU_BACKEND:\n",
    "    os.environ['PACKBOOST_DISABLE_CUDA'] = '1'\n",
    "else:\n",
    "    os.environ.setdefault('PACKBOOST_DISABLE_CUDA', '0')\n",
    "\n",
    "# Build native frontier backend\n",
    "!pip install -q pybind11\n",
    "%cd /content\n",
    "if not (Path('PackBoost').exists()):\n",
    "    !git clone {REPO_URL} PackBoost\n",
    "%cd PackBoost\n",
    "!python3 setup_native.py build_ext --inplace\n",
    "!pip install -q -e .\n",
    "import sys; sys.path.append('/content/PackBoost')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Numerai data\n",
    "This cell pulls the v5.0 training and validation data. Set your API keys if\n",
    "you plan to upload diagnostics at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numerapi import NumerAPI\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"numerai-data\")\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "napi = NumerAPI()\n",
    "napi.download_dataset('v5.0/train.parquet', str(DATA_DIR / 'train.parquet'))\n",
    "napi.download_dataset('v5.0/validation.parquet', str(DATA_DIR / 'validation.parquet'))\n",
    "napi.download_dataset('v5.0/features.json', str(DATA_DIR / 'features.json'))\n",
    "\n",
    "train_df = pd.read_parquet(DATA_DIR / 'train.parquet')\n",
    "valid_df = pd.read_parquet(DATA_DIR / 'validation.parquet')\n",
    "features_json = pd.read_json(DATA_DIR / 'features.json')\n",
    "feature_list = features_json['feature_sets']['all']\n",
    "\n",
    "# keep recent eras for the demo to speed things up\n",
    "train_df = train_df[train_df['era'] >= train_df['era'].max() - 10]\n",
    "valid_df = valid_df[valid_df['era'] >= valid_df['era'].max() - 4]\n",
    "\n",
    "print('Train shape:', train_df.shape)\n",
    "print('Valid shape:', valid_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning and feature prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from packboost import PackBoost, PackBoostConfig\n",
    "\n",
    "X_train = train_df[feature_list].astype(np.int8).values\n",
    "y_train = train_df['target'].astype(np.float32).values\n",
    "era_train = train_df['era'].astype(np.int16).values\n",
    "\n",
    "X_valid = valid_df[feature_list].astype(np.int8).values\n",
    "y_valid = valid_df['target'].astype(np.float32).values\n",
    "era_valid = valid_df['era'].astype(np.int16).values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train PackBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "class LoggingCallback:\n",
    "    def __init__(self, every: int = 5, print_train: bool = False) -> None:\n",
    "        self.every = max(1, int(every))\n",
    "        self.print_train = print_train\n",
    "        self.logs: List[dict] = []\n",
    "\n",
    "    def _record(self, info: dict) -> None:\n",
    "        self.logs.append(\n",
    "            {\n",
    "                \"round\": int(info.get(\"round\", 0)),\n",
    "                \"train_corr\": float(info.get(\"train_corr\", 0.0)),\n",
    "                \"valid_corr\": float(info.get(\"valid_corr\", np.nan)),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def on_round(self, booster, info: dict) -> None:\n",
    "        round_idx = int(info.get(\"round\", 0))\n",
    "        if round_idx % self.every != 0:\n",
    "            return\n",
    "        train_corr = float(info.get(\"train_corr\", 0.0))\n",
    "        valid_corr = info.get(\"valid_corr\")\n",
    "\n",
    "        metrics_parts: List[str] = []\n",
    "        if self.print_train and np.isfinite(train_corr):\n",
    "            metrics_parts.append(f\"train corr = {train_corr:.4f}\")\n",
    "        if valid_corr is not None:\n",
    "            if np.isfinite(valid_corr):\n",
    "                metrics_parts.append(f\"valid corr = {float(valid_corr):.4f}\")\n",
    "            else:\n",
    "                metrics_parts.append(\"valid corr = nan\")\n",
    "        elif self.print_train and not metrics_parts:\n",
    "            metrics_parts.append(f\"train corr = {train_corr:.4f}\")\n",
    "\n",
    "        if metrics_parts:\n",
    "            print(f\"Round {round_idx}: {', '.join(metrics_parts)}\")\n",
    "        self._record(info)\n",
    "\n",
    "    __call__ = on_round\n",
    "\n",
    "    def to_frame(self):\n",
    "        import pandas as pd\n",
    "        return pd.DataFrame(self.logs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from packboost import PackBoost, PackBoostConfig\n",
    "from packboost import backends as pb_backends\n",
    "from packboost.backends import cuda_available\n",
    "from sklearn.metrics import r2_score\n",
    "import time\n",
    "\n",
    "device = 'cuda' if cuda_available() else 'cpu'\n",
    "config = PackBoostConfig(\n",
    "    pack_size=8,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    lambda_l2=1.0,\n",
    "    lambda_dro=0.5,\n",
    "    max_bins=128,\n",
    "    min_samples_leaf=32,\n",
    "    random_state=42,\n",
    "    layer_feature_fraction=0.5,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "booster = PackBoost(config)\n",
    "callback = LoggingCallback(every=5, print_train=True)\n",
    "start = time.perf_counter()\n",
    "booster.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    era_train,\n",
    "    num_rounds=20,\n",
    "    eval_set=(X_valid, y_valid, era_valid),\n",
    "    callbacks=[callback],\n",
    ")\n",
    "fit_time = time.perf_counter() - start\n",
    "\n",
    "start = time.perf_counter()\n",
    "preds = booster.predict(X_valid)\n",
    "metrics = callback.to_frame()\n",
    "metrics.head()\n",
    "pred_time = time.perf_counter() - start\n",
    "\n",
    "native_frontier = getattr(pb_backends, 'cuda_frontier_evaluate', None) is not None\n",
    "print(f'CUDA frontier available: {native_frontier}')\n",
    "print(f'Using GPU frontier: {booster._use_gpu}')\n",
    "print(f'Device requested: {device}')\n",
    "print(f'Fit time: {fit_time:.2f}s')\n",
    "print(f'Predict time: {pred_time:.2f}s')\n",
    "print(f'Validation R^2: {r2_score(y_valid, preds):.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload diagnostics (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide your credentials to upload to Numerai\n",
    "# napi = NumerAPI(public_id='PUBLIC', secret_key='SECRET')\n",
    "# submission = pd.DataFrame({'prediction': preds}).clip(0, 1)\n",
    "# submission.to_csv('packboost_preds.csv', index=False)\n",
    "# napi.upload_diagnostics('packboost_preds.csv', model_id='YOUR_MODEL_ID')\n",
    "print('Diagnostics upload skipped.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot validation correlation over rounds\n",
    "import matplotlib.pyplot as plt\n",
    "if not metrics.empty:\n",
    "    metrics.plot(x='round', y='corr', marker='o')\n",
    "    plt.title('Validation correlation per round')\n",
    "    plt.xlabel('Trees built')\n",
    "    plt.ylabel('Correlation')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No metrics logged (adjust callback frequency).')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}