{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "r-xZlzUtk22u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmWJQuy0GxLl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd663bf9-9e50-4b7e-8d8b-3adca05ead14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numerapi in /usr/local/lib/python3.10/dist-packages (2.19.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from numerapi) (2.32.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from numerapi) (2024.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from numerapi) (2.8.2)\n",
            "Requirement already satisfied: tqdm>=4.29.1 in /usr/local/lib/python3.10/dist-packages (from numerapi) (4.66.5)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from numerapi) (8.1.7)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from numerapi) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->numerapi) (1.26.4)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->numerapi) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->numerapi) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->numerapi) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->numerapi) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->numerapi) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->numerapi) (2024.8.30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "!pip install numerapi\n",
        "\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numerapi import NumerAPI\n",
        "import random\n",
        "import sklearn\n",
        "import time\n",
        "import lightgbm\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "\n",
        "from numba import cuda, jit\n",
        "import numba\n",
        "\n",
        "\n",
        "\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloads"
      ],
      "metadata": {
        "id": "b4S9iVFPlDpq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmZxeMFcGxLs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e3c86e12-8b5d-489c-d08a-b4f5b3579b65"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'v5.0/validation_example_preds.parquet'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "your_public_id = \"\"\n",
        "your_secret_key = \"\"\n",
        "your_model_slot_name = \"\"\n",
        "\n",
        "\n",
        "\n",
        "napi = NumerAPI(your_public_id, your_secret_key)\n",
        "\n",
        "current_round = napi.get_current_round()\n",
        "\n",
        "napi.download_dataset('v5.0/features.json')\n",
        "napi.download_dataset('v5.0/train.parquet')\n",
        "napi.download_dataset('v5.0/validation.parquet')\n",
        "napi.download_dataset('v5.0/validation_example_preds.parquet')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "UljfsEI3lqCV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2kEawfHZ2xi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e30774ff-1cd5-480e-9320-99916899f7a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "ff =  json.load(open('v5.0/features.json', 'rb'))\n",
        "\n",
        "\n",
        "fs = ff['feature_sets']['all']\n",
        "\n",
        "\n",
        "df_train = pd.read_parquet('v5.0/train.parquet')\n",
        "\n",
        "df_train['era'] = df_train['era'].astype(int)\n",
        "\n",
        "\n",
        "df_train = df_train[df_train.era < df_train.era.max() - 4]\n",
        "\n",
        "Xt = df_train[fs].fillna(2).astype(np.uint8).values\n",
        "Yt = df_train['target'].fillna(0).values\n",
        "Yt = 2*Yt - 1\n",
        "Et = df_train['era'].values\n",
        "\n",
        "del df_train\n",
        "gc.collect()\n",
        "\n",
        "df_valid = pd.read_parquet('v5.0/validation.parquet')\n",
        "\n",
        "Xv = df_valid[fs].fillna(2).astype(np.uint8).values\n",
        "Yv = df_valid['target'].fillna(0).values\n",
        "Yv = 2*Yv - 1\n",
        "Ev = df_valid['era'].values\n",
        "\n",
        "\n",
        "\n",
        "df_sub = df_valid[[]]\n",
        "\n",
        "del df_valid\n",
        "gc.collect()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cuda Model Definition"
      ],
      "metadata": {
        "id": "FPjepAyskQDG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8WVWkTb3H4j"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class ExtraFastBooster(object):\n",
        "\n",
        "  def __init__(self, trees_per_layer=8, max_depth=6, nfeatsets=8, lr=.01, L2=10_000, qgrad_bits=12 ):\n",
        "\n",
        "    self.L2 = L2\n",
        "    self.lr = lr\n",
        "    self.max_depth = max_depth\n",
        "    self.nfeatsets = nfeatsets\n",
        "    self.nfolds = trees_per_layer\n",
        "\n",
        "\n",
        "    qgrad_mbits = qgrad_bits - 1\n",
        "\n",
        "\n",
        "    if   max_depth > 8:\n",
        "      packed_tree_dtype = np.uint64\n",
        "    elif max_depth > 6:\n",
        "      packed_tree_dtype = np.uint32\n",
        "    else:\n",
        "      packed_tree_dtype = np.uint16\n",
        "\n",
        "    if max_depth > 8 :\n",
        "      tree_dtype = np.uint16\n",
        "    else:\n",
        "      tree_dtype = np.uint8\n",
        "\n",
        "\n",
        "\n",
        "    grad_dtype        = ( np.int16 if qgrad_mbits>7 else np.int8   )\n",
        "    grad_mbits        = (       15 if qgrad_mbits>7 else       7   )\n",
        "    ymax_lg2          = 30\n",
        "\n",
        "\n",
        "\n",
        "    residual_sm_a100 = 15 - 2 - 6 - max_depth\n",
        "\n",
        "\n",
        "    assert( residual_sm_a100 >= 0 )\n",
        "\n",
        "\n",
        "\n",
        "    hist_warps_per_block_lg2 = max( 4 - max( residual_sm_a100, 0), 0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    self.grad_dtype = grad_dtype\n",
        "    self.tree_dtype = tree_dtype\n",
        "    self.packed_tree_dtype = packed_tree_dtype\n",
        "    self.hist_warps_per_block = 1 << hist_warps_per_block_lg2\n",
        "\n",
        "\n",
        "\n",
        "    @cuda.jit\n",
        "    def _et_sample_1b(  X, XS, F, tree_set, stride, ):\n",
        "\n",
        "      f0 = cuda.blockIdx.x\n",
        "      bi = cuda.blockIdx.y\n",
        "      wi = cuda.threadIdx.x\n",
        "\n",
        "\n",
        "\n",
        "      fs = cuda.shared.array(shape=32, dtype=np.uint32)\n",
        "      sm = cuda.shared.array(shape=( 32, 32 ), dtype=np.uint32)\n",
        "\n",
        "\n",
        "      fs[wi] = F[tree_set, 32*f0 + wi]\n",
        "\n",
        "      cuda.syncwarp()\n",
        "\n",
        "\n",
        "      for i in range(stride):\n",
        "\n",
        "\n",
        "        i_in = 32*stride*bi + 32*i + wi\n",
        "\n",
        "\n",
        "        if 32*stride*bi + 32*i < X.shape[1]:\n",
        "\n",
        "\n",
        "\n",
        "          for k in range(4):\n",
        "            ff0 = fs[8*k + 0]\n",
        "            ff1 = fs[8*k + 1]\n",
        "            ff2 = fs[8*k + 2]\n",
        "            ff3 = fs[8*k + 3]\n",
        "            ff4 = fs[8*k + 4]\n",
        "            ff5 = fs[8*k + 5]\n",
        "            ff6 = fs[8*k + 6]\n",
        "            ff7 = fs[8*k + 7]\n",
        "\n",
        "            kk0 = (wi + 8*k + 0)%32\n",
        "            kk1 = (wi + 8*k + 1)%32\n",
        "            kk2 = (wi + 8*k + 2)%32\n",
        "            kk3 = (wi + 8*k + 3)%32\n",
        "            kk4 = (wi + 8*k + 4)%32\n",
        "            kk5 = (wi + 8*k + 5)%32\n",
        "            kk6 = (wi + 8*k + 6)%32\n",
        "            kk7 = (wi + 8*k + 7)%32\n",
        "\n",
        "            v0 = ( X[ff0, i_in] if i_in < X.shape[1] else 0 )\n",
        "            v1 = ( X[ff1, i_in] if i_in < X.shape[1] else 0 )\n",
        "            v2 = ( X[ff2, i_in] if i_in < X.shape[1] else 0 )\n",
        "            v3 = ( X[ff3, i_in] if i_in < X.shape[1] else 0 )\n",
        "            v4 = ( X[ff4, i_in] if i_in < X.shape[1] else 0 )\n",
        "            v5 = ( X[ff5, i_in] if i_in < X.shape[1] else 0 )\n",
        "            v6 = ( X[ff6, i_in] if i_in < X.shape[1] else 0 )\n",
        "            v7 = ( X[ff7, i_in] if i_in < X.shape[1] else 0 )\n",
        "\n",
        "            sm[8*k+0, kk0] = v0\n",
        "            sm[8*k+1, kk1] = v1\n",
        "            sm[8*k+2, kk2] = v2\n",
        "            sm[8*k+3, kk3] = v3\n",
        "            sm[8*k+4, kk4] = v4\n",
        "            sm[8*k+5, kk5] = v5\n",
        "            sm[8*k+6, kk6] = v6\n",
        "            sm[8*k+7, kk7] = v7\n",
        "\n",
        "\n",
        "\n",
        "          cuda.syncwarp()\n",
        "\n",
        "          for k in range(32):\n",
        "            i_out = 32*32*stride*bi + 32*32*i + 32*k + wi\n",
        "\n",
        "            kk = (k + wi)%32\n",
        "\n",
        "            XS[f0, i_out] =  sm[wi, kk]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    @cuda.jit\n",
        "    def _prep_vars(  L, LE, Y, P, G, stride ):\n",
        "\n",
        "      ti = cuda.blockIdx.x\n",
        "      wi = cuda.threadIdx.x\n",
        "\n",
        "\n",
        "      for i in range( stride ):\n",
        "\n",
        "        j = 32*stride*ti + 32*i + wi\n",
        "\n",
        "\n",
        "        if j < Y.shape[0]:\n",
        "\n",
        "\n",
        "          for k in range(LE.shape[0]):\n",
        "\n",
        "            v = packed_tree_dtype(0)\n",
        "            for d in range(1, max_depth):\n",
        "              v |= L[ k, d-1, j]  << ( ( d*(d-1) )//2 )\n",
        "\n",
        "            LE[k, j] = v\n",
        "\n",
        "\n",
        "\n",
        "          g = ( np.int64(Y[j]) - np.int64(P[j]) ) >> ( 31 - qgrad_mbits )\n",
        "\n",
        "          g = min( max(g, - ( 1 << grad_mbits ) + 1 ), ( 1 << grad_mbits) - 1 )\n",
        "\n",
        "          G[j] = grad_dtype( g )\n",
        "\n",
        "      return\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    fstmem = ( 8, max_depth-1, 32 )\n",
        "\n",
        "\n",
        "    @cuda.jit\n",
        "    def _repack_trees_for_features( FST,  LE, LF, tree_set, stride ):\n",
        "\n",
        "      fi = cuda.blockIdx.x\n",
        "      ti = cuda.blockIdx.y\n",
        "      wi = cuda.threadIdx.x\n",
        "\n",
        "      fst = cuda.shared.array( shape=fstmem,     dtype=np.uint32)\n",
        "\n",
        "      trees = cuda.shared.array( shape=(20, 32), dtype= packed_tree_dtype )\n",
        "\n",
        "\n",
        "      for k in range(8):\n",
        "        if 8*fi + k < FST.shape[1]:\n",
        "          for d in range(1, FST.shape[2]):\n",
        "            fst[k, d-1, wi] = FST[tree_set, 8*fi + k, d]\n",
        "\n",
        "\n",
        "\n",
        "      for i in range( stride ):\n",
        "\n",
        "        j = 32*stride*ti + 32*i + wi\n",
        "\n",
        "        if j < LF.shape[1]:\n",
        "\n",
        "\n",
        "          for k in range(LE.shape[0]):\n",
        "            trees[k,wi] = LE[k, j]\n",
        "\n",
        "          for k in range(8):\n",
        "\n",
        "            if 8*fi + k < LF.shape[0]:\n",
        "              v = 0\n",
        "              for d in range(1, FST.shape[2]):\n",
        "                v |= trees[ fst[k, d-1, wi], wi ] & (  (  ( 1 << d ) - 1 ) << (  (d * (d-1))//2  )    )\n",
        "\n",
        "              LF[8*fi + k, j] = v\n",
        "\n",
        "      return\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    flocal_hist_shape = ( 1<<max_depth, 2, 32 )\n",
        "    @cuda.jit\n",
        "    def _unweighted_featureless_histogram(Y, LE, H0, stride):\n",
        "\n",
        "      tree_set = cuda.blockIdx.x\n",
        "      ti       = cuda.blockIdx.y\n",
        "\n",
        "      wi = cuda.threadIdx.x\n",
        "\n",
        "      hist  = cuda.shared.array( shape=flocal_hist_shape,  dtype=np.int32 )\n",
        "\n",
        "\n",
        "      for i in range( 1<<max_depth ):\n",
        "        hist[i, 0, wi] = 0\n",
        "        hist[i, 1, wi] = 0\n",
        "\n",
        "\n",
        "\n",
        "      for j in range( stride ):\n",
        "        jj = 32*stride*ti + 32*j + wi\n",
        "\n",
        "        if jj < Y.shape[0]:\n",
        "\n",
        "\n",
        "          lk = LE[tree_set,  jj]\n",
        "          y  = Y [           jj]\n",
        "\n",
        "\n",
        "          for d in range(max_depth):\n",
        "            to = ( 1 << d ) - 1\n",
        "            tk = lk & to\n",
        "            lk = lk >> d\n",
        "\n",
        "            hist[ to + tk,  0, wi ] += y\n",
        "            hist[ to + tk,  1, wi ] += 1\n",
        "\n",
        "\n",
        "\n",
        "      for k in range( (1<<max_depth) - 1 ):\n",
        "\n",
        "        cuda.atomic.add( H0, (tree_set, k, 0, ), np.int64( hist[k, 0, wi] ) )\n",
        "        cuda.atomic.add( H0, (tree_set, k, 1, ),           hist[k, 1, wi] )\n",
        "\n",
        "      return\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    shared_hist_shape = (  max( (1<<max_depth) - (1<<3),1) , 2, 32 )\n",
        "\n",
        "\n",
        "    @cuda.jit\n",
        "    def _unweighted_histogram(XS, Y, L, H, warps_per_block, stride):\n",
        "\n",
        "      feat_set  = cuda.blockIdx.x\n",
        "      ti        = cuda.blockIdx.y\n",
        "\n",
        "\n",
        "      wi         = cuda.threadIdx.x & 31\n",
        "      bi         = cuda.threadIdx.x >> 5\n",
        "\n",
        "      ti = warps_per_block*ti + bi\n",
        "\n",
        "\n",
        "\n",
        "      hf0 = np.int32(0)\n",
        "      hw0 = np.int32(0)\n",
        "\n",
        "      hf10 = np.int32(0)\n",
        "      hf11 = np.int32(0)\n",
        "      hw10 = np.int32(0)\n",
        "      hw11 = np.int32(0)\n",
        "\n",
        "\n",
        "      hf20 = np.int32(0)\n",
        "      hf21 = np.int32(0)\n",
        "      hf22 = np.int32(0)\n",
        "      hf23 = np.int32(0)\n",
        "      hw20 = np.int32(0)\n",
        "      hw21 = np.int32(0)\n",
        "      hw22 = np.int32(0)\n",
        "      hw23 = np.int32(0)\n",
        "\n",
        "\n",
        "      shared_hist = cuda.shared.array(shape=shared_hist_shape, dtype=np.int32)\n",
        "\n",
        "\n",
        "      for i in range( (1<<max_depth) - (1<<3) ):\n",
        "        shared_hist[i, 0, wi] = 0\n",
        "        shared_hist[i, 1, wi] = 0\n",
        "\n",
        "\n",
        "\n",
        "      cuda.syncthreads()\n",
        "\n",
        "\n",
        "\n",
        "      for j in range( stride ):\n",
        "\n",
        "          if 32*(stride*ti + j) < XS.shape[1]:\n",
        "\n",
        "            jj = 32*stride*ti + 32*j + wi\n",
        "\n",
        "            if jj < Y.shape[0]:\n",
        "              lvd = L[feat_set,  jj]\n",
        "              y  = np.int32(Y[        jj])\n",
        "\n",
        "            xfd = XS[feat_set, jj]\n",
        "\n",
        "\n",
        "            for k in range(32):\n",
        "\n",
        "              jj = 32*stride*ti + 32*j + k\n",
        "\n",
        "\n",
        "              if jj < Y.shape[0]:\n",
        "\n",
        "                v   = np.int32( xfd  & 1 )\n",
        "                xfd = xfd >> 1\n",
        "\n",
        "\n",
        "                yk = cuda.shfl_sync( -1,   y, k )\n",
        "                lk = cuda.shfl_sync( -1, lvd, k )\n",
        "\n",
        "\n",
        "                #d0\n",
        "                hf0 += v*yk\n",
        "                hw0 += v\n",
        "\n",
        "                #d1\n",
        "                tk = lk & 1\n",
        "\n",
        "                if tk==0:\n",
        "                  hf10 += v*yk\n",
        "                  hw10 += v\n",
        "                else:\n",
        "                  hf11 += v*yk\n",
        "                  hw11 += v\n",
        "\n",
        "                lk = lk >> 1\n",
        "\n",
        "                #d2\n",
        "                tk = lk  & 3\n",
        "\n",
        "                if   tk==0:\n",
        "                  hf20 += v*yk\n",
        "                  hw20 += v\n",
        "                elif tk==1:\n",
        "                  hf21 += v*yk\n",
        "                  hw21 += v\n",
        "                elif tk==2:\n",
        "                  hf22 += v*yk\n",
        "                  hw22 += v\n",
        "                else:\n",
        "                  hf23 += v*yk\n",
        "                  hw23 += v\n",
        "\n",
        "                lk = lk >> 2\n",
        "\n",
        "\n",
        "\n",
        "                for d in range( 3, max_depth ):\n",
        "                  to = ( 1 << d ) - 1\n",
        "                  tk = lk & to\n",
        "                  lk = lk >> d\n",
        "\n",
        "                  cuda.atomic.add( shared_hist, (to + tk - 7,  0,  wi ), v*yk )\n",
        "                  cuda.atomic.add( shared_hist, (to + tk - 7,  1,  wi ), v    )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      cuda.atomic.add( H, (feat_set, 0, 0, wi), hf0)\n",
        "\n",
        "      cuda.atomic.add( H, (feat_set, 0, 1, wi), hw0)\n",
        "\n",
        "\n",
        "      cuda.atomic.add( H, (feat_set, 1, 0, wi), hf10)\n",
        "      cuda.atomic.add( H, (feat_set, 2, 0, wi), hf11)\n",
        "\n",
        "      cuda.atomic.add( H, (feat_set, 1, 1, wi), hw10)\n",
        "      cuda.atomic.add( H, (feat_set, 2, 1, wi), hw11)\n",
        "\n",
        "\n",
        "      cuda.atomic.add( H, (feat_set, 3, 0, wi), hf20)\n",
        "      cuda.atomic.add( H, (feat_set, 4, 0, wi), hf21)\n",
        "      cuda.atomic.add( H, (feat_set, 5, 0, wi), hf22)\n",
        "      cuda.atomic.add( H, (feat_set, 6, 0, wi), hf23)\n",
        "\n",
        "      cuda.atomic.add( H, (feat_set, 3, 1, wi), hw20)\n",
        "      cuda.atomic.add( H, (feat_set, 4, 1, wi), hw21)\n",
        "      cuda.atomic.add( H, (feat_set, 5, 1, wi), hw22)\n",
        "      cuda.atomic.add( H, (feat_set, 6, 1, wi), hw23)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      cuda.syncthreads()\n",
        "\n",
        "      n = (1<<max_depth) - 8\n",
        "      w = ( n + warps_per_block - 1 ) // warps_per_block\n",
        "\n",
        "      for k in range( w ):\n",
        "\n",
        "        i = w*bi + k + 7\n",
        "\n",
        "        if i < H.shape[1]:\n",
        "\n",
        "          cuda.atomic.add( H, (feat_set, i, 0, wi), np.int64( shared_hist[ i - 7, 0, wi] ) )\n",
        "          cuda.atomic.add( H, (feat_set, i, 1, wi),           shared_hist[ i - 7, 1, wi] )\n",
        "\n",
        "      return\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    @cuda.jit\n",
        "    def _cut_cuda( F, FST, H, H0, V, I, tree_set, L2, lr):\n",
        "\n",
        "      leaf = cuda.blockIdx.x\n",
        "      wi  = cuda.threadIdx.x\n",
        "\n",
        "\n",
        "      depth = 31 - cuda.clz(  np.uint32( leaf + 1 ) )\n",
        "\n",
        "      mxs = cuda.local.array( shape=( 20 ),     dtype=np.int32)\n",
        "      vrs = cuda.local.array( shape=( 20 ),     dtype=np.int32)\n",
        "      vls = cuda.local.array( shape=( 20 ),     dtype=np.int32)\n",
        "      fs  = cuda.local.array( shape=( 20 ),     dtype=np.uint16)\n",
        "\n",
        "\n",
        "\n",
        "      g01s  = cuda.local.array( shape=( 20 ),     dtype=np.float32)\n",
        "      n01s  = cuda.local.array( shape=( 20 ),     dtype=np.float32)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      for k in range(H0.shape[0]):\n",
        "        mxs[k] = -1e8\n",
        "\n",
        "        g01s[k] =  np.float32( H0[k, leaf, 0] )\n",
        "        n01s[k] =  np.float32( H0[k, leaf, 1] )\n",
        "\n",
        "\n",
        "      L2 = np.float32(L2 ) * 2.**(  5 - depth)\n",
        "\n",
        "\n",
        "\n",
        "      for k in range(H.shape[0]):\n",
        "\n",
        "        tree_fold = FST[tree_set,  k, depth]\n",
        "\n",
        "\n",
        "        G0 = np.float32( H[k, leaf, 0, wi] )\n",
        "        N0 = np.float32( H[k, leaf, 1, wi] )\n",
        "\n",
        "        G01 = g01s[tree_fold]\n",
        "        N01 = n01s[tree_fold]\n",
        "\n",
        "\n",
        "        G1  = G01 - G0\n",
        "        N1  = N01 - N0\n",
        "\n",
        "        V0 = G0 / ( N0 + L2 )\n",
        "        V1 = G1 / ( N1 + L2 )\n",
        "\n",
        "        S0  = G0 * V0\n",
        "        S1  = G1 * V1\n",
        "\n",
        "\n",
        "        S = np.float32( (S0 + S1)   ).view(np.int32)\n",
        "\n",
        "        if ( mxs[tree_fold] < S ):\n",
        "\n",
        "          mxs[tree_fold] = S\n",
        "          vls[tree_fold] = int(  lr * V0 * ( 1 << ( 31 - qgrad_bits ) ) * 2**( - np.float32( max_depth - depth )  )  )\n",
        "          vrs[tree_fold] = int(  lr * V1 * ( 1 << ( 31 - qgrad_bits ) ) * 2**( - np.float32( max_depth - depth )  )  )\n",
        "          fs [tree_fold] = k\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      for tree_fold in range(V.shape[1]):\n",
        "\n",
        "        mx = mxs[tree_fold]\n",
        "\n",
        "        mxw = mx\n",
        "        cuda.syncwarp(-1)\n",
        "\n",
        "        for p in range(5):\n",
        "          v = cuda.shfl_xor_sync(-1, mxw, 1<<p )\n",
        "\n",
        "          mxw = max(v, mxw)\n",
        "\n",
        "        msk = cuda.ballot_sync(-1, mx == mxw )\n",
        "\n",
        "        is_max = ( mx == mxw ) and ( ( 1 << wi ) > ( msk >> 1 ) )\n",
        "\n",
        "\n",
        "\n",
        "        if is_max:\n",
        "\n",
        "          V[tree_set, tree_fold, 2*leaf     ] = vls[tree_fold]\n",
        "          V[tree_set, tree_fold, 2*leaf + 1 ] = vrs[tree_fold]\n",
        "\n",
        "\n",
        "          I [tree_set, tree_fold, leaf ] = F[tree_set, 32*fs[tree_fold] + wi ]\n",
        "\n",
        "      return\n",
        "\n",
        "\n",
        "\n",
        "    @cuda.jit\n",
        "    def _advance_and_predict( P, X, L_old, L_new, V, I, stride, tree_set,):\n",
        "\n",
        "      tree_fold = cuda.blockIdx.x\n",
        "      depth     = cuda.blockIdx.y\n",
        "      i         = cuda.blockIdx.z\n",
        "\n",
        "      wi = cuda.threadIdx.x\n",
        "\n",
        "      for j in range(stride):\n",
        "        k = 32*stride*i + 32*j + wi\n",
        "\n",
        "        if k < L_old.shape[2]:\n",
        "\n",
        "          leaf = np.uint16( L_old[tree_fold, depth-1, k] if depth > 0 else 0 )\n",
        "\n",
        "          lo = leaf + (1<<depth) - 1\n",
        "\n",
        "          li = I[tree_set, tree_fold, lo]\n",
        "\n",
        "\n",
        "          x = ( X[li, k>>5] >> ( k&31  ) ) & 1\n",
        "\n",
        "\n",
        "          leaf =  2*leaf + x\n",
        "\n",
        "          if depth < L_new.shape[1]:\n",
        "            L_new[tree_fold, depth, k] = tree_dtype( leaf )\n",
        "\n",
        "\n",
        "          cuda.atomic.add( P, k, V[tree_set, tree_fold, 2*lo + 1 + x ] )\n",
        "\n",
        "      return\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    self._et_sample                        = _et_sample_1b\n",
        "    self._prep_vars                        = _prep_vars\n",
        "    self._repack_trees_for_features        = _repack_trees_for_features\n",
        "    self._unweighted_featureless_histogram = _unweighted_featureless_histogram\n",
        "    self._unweighted_histogram             =  _unweighted_histogram\n",
        "    self._cut_cuda                         = _cut_cuda\n",
        "    self._advance_and_predict              = _advance_and_predict\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    self.tree_set = 0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def _fit(self, rounds):\n",
        "\n",
        "\n",
        "    for k in range(rounds):\n",
        "\n",
        "      assert(self.tree_set < self.dFST.shape[0])\n",
        "\n",
        "      self.dH  = cuda.to_device( np.zeros([self.nfeatsets, 2**self.max_depth, 2, 32 ], dtype=np.int64) )\n",
        "\n",
        "\n",
        "      self.dH0 = cuda.to_device( np.zeros([self.nfolds,     2**self.max_depth, 2     ], dtype=np.int64) )\n",
        "\n",
        "\n",
        "\n",
        "      strides = 256\n",
        "\n",
        "      stride = int( np.ceil( self.dXS.shape[1] / strides / 32 ) )\n",
        "\n",
        "      self._et_sample[ ( self.nfeatsets , strides), 32](  self.dX, self.dXS, self.dF,  self.tree_set, stride )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      strides = 512\n",
        "\n",
        "      stride = int( np.ceil( self.dY.shape[0] / strides / 32 ) )\n",
        "\n",
        "      self._prep_vars[strides, 32](  self.dL, self.dLE, self.dY, self.dP, self.dG, stride )\n",
        "\n",
        "\n",
        "\n",
        "      strides = 1024\n",
        "\n",
        "      stride = int( np.ceil( self.dY.shape[0] / strides / 32 ) )\n",
        "\n",
        "      self._repack_trees_for_features[( (self.dFST.shape[1]+7)//8, strides), 32]( self.dFST,  self.dLE, self.dLF, self.tree_set, stride )\n",
        "\n",
        "\n",
        "\n",
        "      warps_per_block = self.hist_warps_per_block\n",
        "      blocks_per_feat =  ( (64*103 )//warps_per_block + self.nfeatsets - 1) // self.nfeatsets\n",
        "\n",
        "      strides = blocks_per_feat * warps_per_block\n",
        "\n",
        "      stride = int( np.ceil( self.dXS.shape[1] / strides / 32 ) )\n",
        "\n",
        "      self._unweighted_histogram[ ( self.dXS.shape[0], blocks_per_feat), warps_per_block*32](self.dXS, self.dG, self.dLF, self.dH, warps_per_block, stride )\n",
        "\n",
        "\n",
        "      strides = 512\n",
        "\n",
        "      stride = int( np.ceil( self.dY.shape[0] / strides / 32 ) )\n",
        "\n",
        "      self._unweighted_featureless_histogram[(self.nfolds, strides), 32](self.dG, self.dLE, self.dH0, stride )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      self._cut_cuda[2**self.max_depth - 1, 32](  self.dF, self.dFST, self.dH, self.dH0, self.dV, self.dI, self.tree_set, self.L2, self.lr/ self.nfolds)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      strides = 512\n",
        "\n",
        "      stride = int( np.ceil( self.dP.shape[0] / strides / 32 ) )\n",
        "\n",
        "      self._advance_and_predict[(self.nfolds, min(self.tree_set+1, self.max_depth), strides), 32 ]( self.dP, self.dX, self.dL, self.dLn, self.dV, self.dI,  stride, self.tree_set)\n",
        "\n",
        "\n",
        "      self.dL, self.dLn = self.dLn, self.dL\n",
        "\n",
        "\n",
        "      if self.dXv is not None:\n",
        "\n",
        "        stride = int( np.ceil( self.dPv.shape[0] / strides / 32 ) )\n",
        "\n",
        "        self._advance_and_predict[(self.nfolds, min(self.tree_set+1, self.max_depth), strides), 32 ]( self.dPv, self.dXv, self.dLv, self.dLvn, self.dV, self.dI,  stride, self.tree_set)\n",
        "\n",
        "\n",
        "        self.dLv, self.dLvn = self.dLvn, self.dLv\n",
        "\n",
        "\n",
        "      for callback in self.callbacks:\n",
        "        callback(self)\n",
        "\n",
        "\n",
        "      self.tree_set = self.tree_set + 1\n",
        "\n",
        "\n",
        "\n",
        "  def fit(self, X, Y, Xv=None, Yv=None,  F=None, FST=None, C=None, rounds=None, callbacks=[] ):\n",
        "\n",
        "\n",
        "    rounds = ( F.shape[0] if rounds is None else rounds )\n",
        "\n",
        "\n",
        "\n",
        "    self.callbacks = callbacks\n",
        "\n",
        "    self.dX  = cuda.to_device( X  )\n",
        "\n",
        "    self.dXS = cuda.to_device(np.zeros([ self.nfeatsets,  32*X.shape[1] ], np.uint32))\n",
        "\n",
        "\n",
        "    self.dH0 = cuda.to_device( np.zeros([ self.nfolds,  2**self.max_depth,  2 ], dtype=np.int64) )\n",
        "\n",
        "\n",
        "\n",
        "    self.dF = cuda.to_device(F)\n",
        "\n",
        "    self.dL  = cuda.to_device( np.zeros([self.nfolds, self.max_depth-1, Y.shape[0]], dtype=np.uint8 ) )\n",
        "    self.dLE = cuda.to_device( np.zeros([self.nfolds,                   Y.shape[0]], dtype=self.packed_tree_dtype ) )\n",
        "\n",
        "    self.dY = cuda.to_device( (Y*(1<<30)).astype(np.int32) )\n",
        "    self.dP = cuda.to_device( np.zeros(Y.shape, dtype=np.int32) )\n",
        "    self.dG = cuda.to_device( np.zeros(Y.shape, dtype=self.grad_dtype ) )\n",
        "\n",
        "    self.dH   = cuda.to_device( np.zeros([self.nfeatsets, 2**self.max_depth, 2, 32 ], dtype=np.int64) )\n",
        "    self.dLF  = cuda.to_device( np.zeros([self.nfeatsets, Y.shape[0] ], dtype=self.packed_tree_dtype ) )\n",
        "    self.dFST = cuda.to_device(FST.astype(np.uint8))\n",
        "\n",
        "\n",
        "\n",
        "    self.dV = cuda.to_device(np.zeros([rounds, self.nfolds, 2*(2**self.max_depth - 1)], dtype=np.int32 ))\n",
        "    self.dI = cuda.to_device(np.zeros([rounds, self.nfolds,   (2**self.max_depth - 1)], dtype=np.uint16))\n",
        "\n",
        "    self.dLn = cuda.to_device( np.zeros(self.dL.shape, dtype=self.tree_dtype) )\n",
        "\n",
        "\n",
        "    if Xv is not None:\n",
        "\n",
        "      self.dXv = cuda.to_device( Xv )\n",
        "\n",
        "      self.dPv = cuda.to_device( np.zeros(Yv.shape, dtype=np.int32) )\n",
        "      self.Yv = Yv\n",
        "\n",
        "      self.dLv  = cuda.to_device( np.zeros([self.nfolds, self.max_depth-1, Yv.shape[0]], dtype=self.tree_dtype) )\n",
        "      self.dLvn = cuda.to_device( np.zeros([self.nfolds, self.max_depth-1, Yv.shape[0]], dtype=self.tree_dtype) )\n",
        "    else:\n",
        "      self.dXv = None\n",
        "\n",
        "\n",
        "    self._fit(rounds)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def predict(self, X, shape=None):\n",
        "\n",
        "\n",
        "    if shape is None:\n",
        "      shape = 32*X.shape[1]\n",
        "\n",
        "    dX  = cuda.to_device( X )\n",
        "    dL  = cuda.to_device( np.zeros([self.nfolds, self.max_depth-1, shape], dtype=self.tree_dtype ) )\n",
        "    dLn = cuda.to_device( np.zeros([self.nfolds, self.max_depth-1, shape], dtype=self.tree_dtype ) )\n",
        "    dP  = cuda.to_device( np.zeros([shape], dtype=np.int32 ) )\n",
        "\n",
        "\n",
        "    for k in range( self.tree_set ):\n",
        "\n",
        "      strides = 256\n",
        "\n",
        "      stride = int( np.ceil( dP.shape[0] / strides / 32 ) )\n",
        "\n",
        "      self._advance_and_predict[(self.nfolds, min(k+1, self.max_depth), strides), 32 ]( dP, dX, dL, dLn, self.dV, self.dI,  stride, k)\n",
        "\n",
        "      dL, dLn = dLn, dL\n",
        "\n",
        "    p = dP.copy_to_host()\n",
        "\n",
        "    del dX, dL, dLn, dP\n",
        "\n",
        "    return p\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def save(self, path):\n",
        "\n",
        "    V = self.dV.copy_to_host()\n",
        "    I = self.dI.copy_to_host()\n",
        "\n",
        "    V = V[:self.tree_set]\n",
        "    I = I[:self.tree_set]\n",
        "\n",
        "    np.savez(path, V=V, I=I)\n",
        "\n",
        "\n",
        "  def load(self, path):\n",
        "\n",
        "    data = np.load(path)\n",
        "\n",
        "    self.dV = cuda.to_device(data['V'])\n",
        "    self.dI = cuda.to_device(data['I'])\n",
        "\n",
        "    self.tree_set = self.dV.shape[0]\n",
        "    self.nfolds   = self.dV.shape[1]\n",
        "    self.max_depth = int.bit_count(self.dI.shape[-1])\n",
        "\n",
        "    del data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logger"
      ],
      "metadata": {
        "id": "VtHh0qXhAH_5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_tiOv_4X_Ga"
      },
      "outputs": [],
      "source": [
        "class LoggingCallback(object):\n",
        "\n",
        "  def __init__(self, frequency=500):\n",
        "    self.frequency = frequency\n",
        "    self.val_corrs = []\n",
        "    self.trn_corrs = []\n",
        "\n",
        "  def __call__(self, booster):\n",
        "\n",
        "\n",
        "    round = booster.tree_set + 1\n",
        "\n",
        "    if booster.tree_set == 0:\n",
        "      self.t0 = time.time()\n",
        "      self.t  = self.t0\n",
        "\n",
        "    if round % self.frequency == 0:\n",
        "\n",
        "      ct =  np.corrcoef( booster.dP.copy_to_host(), booster.dY.copy_to_host() )[0,1]\n",
        "\n",
        "      print( 'Round: {}  ---  Trees {}'.format( round, booster.nfolds*round ) )\n",
        "      print()\n",
        "      print( 'Train Corr: {:.4f}'.format(ct) )\n",
        "\n",
        "      self.trn_corrs.append( ct )\n",
        "\n",
        "      if booster.dXv is not None:\n",
        "        pv = booster.dPv.copy_to_host()\n",
        "        yv = booster.Yv\n",
        "\n",
        "        cv = np.corrcoef( pv, yv )[0,1]\n",
        "\n",
        "        print( 'Valid Corr: {:.4f}'.format(cv) )\n",
        "\n",
        "\n",
        "        self.val_corrs.append( cv )\n",
        "\n",
        "      elapsed = time.time() - self.t0\n",
        "      dt      = time.time() - self.t\n",
        "\n",
        "      print()\n",
        "      print( 'Time: {:.2f}s  --  Step: {:.2f}s  --  TPS: {:.1f}'.format( elapsed, dt, booster.nfolds*self.frequency/dt ) )\n",
        "      print()\n",
        "      print()\n",
        "      print()\n",
        "      self.t = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KfDjWhyokNCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Bitpacked Encoding"
      ],
      "metadata": {
        "id": "S_3nKsZ5dqRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@cuda.jit\n",
        "def _encode_cuts(  X, XB,  stride, ):\n",
        "\n",
        "  f  = cuda.blockIdx.x\n",
        "  bi = cuda.blockIdx.y\n",
        "  wi = cuda.threadIdx.x\n",
        "\n",
        "  sm = cuda.shared.array(shape=( 32, 32 ), dtype=np.uint32)\n",
        "\n",
        "\n",
        "  for i in range(stride):\n",
        "\n",
        "    i_in  = 32*32*stride*bi + 32*32*i +  wi\n",
        "    i_out =    32*stride*bi +    32*i +  wi\n",
        "\n",
        "    v0 = np.uint32(0)\n",
        "    v1 = np.uint32(0)\n",
        "    v2 = np.uint32(0)\n",
        "    v3 = np.uint32(0)\n",
        "\n",
        "\n",
        "    for k in range(32):\n",
        "\n",
        "      sm[wi, (k+wi)%32] = X[f, 32*k + i_in ] if 32*k + i_in < X.shape[1] else 0\n",
        "\n",
        "\n",
        "    for k in range(32):\n",
        "\n",
        "      v = sm[k, (k+wi)%32]\n",
        "\n",
        "      v0 |=  (1 if v>0 else 0 ) << k\n",
        "      v1 |=  (1 if v>1 else 0 ) << k\n",
        "      v2 |=  (1 if v>2 else 0 ) << k\n",
        "      v3 |=  (1 if v>3 else 0 ) << k\n",
        "\n",
        "\n",
        "    if i_out < XB.shape[1]:\n",
        "      XB[4*f + 0, i_out] = v0\n",
        "      XB[4*f + 1, i_out] = v1\n",
        "      XB[4*f + 2, i_out] = v2\n",
        "      XB[4*f + 3, i_out] = v3\n",
        "\n",
        "\n",
        "def encode_cuts(X):\n",
        "\n",
        "  X = (X.T).copy()\n",
        "\n",
        "  strides = 64\n",
        "\n",
        "  dX  = cuda.to_device(X)\n",
        "  dXB = cuda.to_device( np.zeros([4*dX.shape[0], (dX.shape[1]+31)//32  ], dtype=np.uint32) )\n",
        "\n",
        "\n",
        "  stride = int( np.ceil( dX.shape[1] / 32**2 / strides ) )\n",
        "\n",
        "  _encode_cuts[(X.shape[0],  strides), 32 ]( dX, dXB, stride)\n",
        "\n",
        "  X = dXB.copy_to_host()\n",
        "\n",
        "  del dX, dXB\n",
        "  gc.collect()\n",
        "\n",
        "\n",
        "  return X"
      ],
      "metadata": {
        "id": "idnOF0xBk2Y3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Parameters and Feature Pre-Selection"
      ],
      "metadata": {
        "id": "x2Tgx2OonOat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr              = 0.07\n",
        "trees_per_layer = 8\n",
        "nsets     = 10000\n",
        "nfeatsets = 16*2\n",
        "max_depth = 7\n",
        "L2 = 100_000\n",
        "\n",
        "\n",
        "# feature schedule for booster\n",
        "F = np.array( [  np.hstack([ np.tile(np.random.choice(4*Xt.shape[1], 32, replace=True), [1]) for kk in range(nfeatsets)] )\n",
        "                   for k in range(nsets) ] )\n",
        "F = F.astype(np.uint16)\n",
        "\n",
        "\n",
        "# 32 feature subset to tree batch map by depth\n",
        "FST = np.tile( np.tile( np.arange(trees_per_layer), [ (nfeatsets + trees_per_layer - 1)//trees_per_layer  ])[np.newaxis, np.newaxis, :nfeatsets], [nsets, max_depth, 1] )\n",
        "\n",
        "[[np.random.shuffle(FST[k,kk]) for kk in range(max_depth)] for k in range(nsets)];\n",
        "FST = FST.transpose(0,2,1).copy()\n",
        "\n",
        "feats_per_layer = 32 * nfeatsets // trees_per_layer\n",
        "feats_per_layer"
      ],
      "metadata": {
        "id": "U9tQwxatrIW4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c3a6e1d-ab1c-416c-f801-82ad24523a2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "EfxCuPQJkZy6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnbIPEYzlN7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4712d84f-bcd4-4833-9989-ae27dae98234"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 127 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round: 500  ---  Trees 4000\n",
            "\n",
            "Train Corr: 0.1023\n",
            "Valid Corr: 0.0246\n",
            "\n",
            "Time: 15.16s  --  Step: 15.16s  --  TPS: 263.8\n",
            "\n",
            "\n",
            "\n",
            "Round: 1000  ---  Trees 8000\n",
            "\n",
            "Train Corr: 0.1308\n",
            "Valid Corr: 0.0280\n",
            "\n",
            "Time: 30.43s  --  Step: 15.27s  --  TPS: 262.0\n",
            "\n",
            "\n",
            "\n",
            "Round: 1500  ---  Trees 12000\n",
            "\n",
            "Train Corr: 0.1531\n",
            "Valid Corr: 0.0300\n",
            "\n",
            "Time: 45.61s  --  Step: 15.18s  --  TPS: 263.5\n",
            "\n",
            "\n",
            "\n",
            "Round: 2000  ---  Trees 16000\n",
            "\n",
            "Train Corr: 0.1721\n",
            "Valid Corr: 0.0314\n",
            "\n",
            "Time: 60.80s  --  Step: 15.19s  --  TPS: 263.4\n",
            "\n",
            "\n",
            "\n",
            "Round: 2500  ---  Trees 20000\n",
            "\n",
            "Train Corr: 0.1890\n",
            "Valid Corr: 0.0324\n",
            "\n",
            "Time: 75.99s  --  Step: 15.19s  --  TPS: 263.3\n",
            "\n",
            "\n",
            "\n",
            "Round: 3000  ---  Trees 24000\n",
            "\n",
            "Train Corr: 0.2043\n",
            "Valid Corr: 0.0332\n",
            "\n",
            "Time: 91.19s  --  Step: 15.20s  --  TPS: 263.2\n",
            "\n",
            "\n",
            "\n",
            "Round: 3500  ---  Trees 28000\n",
            "\n",
            "Train Corr: 0.2187\n",
            "Valid Corr: 0.0338\n",
            "\n",
            "Time: 106.39s  --  Step: 15.20s  --  TPS: 263.2\n",
            "\n",
            "\n",
            "\n",
            "Round: 4000  ---  Trees 32000\n",
            "\n",
            "Train Corr: 0.2321\n",
            "Valid Corr: 0.0343\n",
            "\n",
            "Time: 121.59s  --  Step: 15.20s  --  TPS: 263.1\n",
            "\n",
            "\n",
            "\n",
            "Round: 4500  ---  Trees 36000\n",
            "\n",
            "Train Corr: 0.2448\n",
            "Valid Corr: 0.0347\n",
            "\n",
            "Time: 136.80s  --  Step: 15.21s  --  TPS: 263.0\n",
            "\n",
            "\n",
            "\n",
            "Round: 5000  ---  Trees 40000\n",
            "\n",
            "Train Corr: 0.2567\n",
            "Valid Corr: 0.0351\n",
            "\n",
            "Time: 152.01s  --  Step: 15.21s  --  TPS: 263.0\n",
            "\n",
            "\n",
            "\n",
            "Round: 5500  ---  Trees 44000\n",
            "\n",
            "Train Corr: 0.2681\n",
            "Valid Corr: 0.0353\n",
            "\n",
            "Time: 167.22s  --  Step: 15.21s  --  TPS: 263.0\n",
            "\n",
            "\n",
            "\n",
            "Round: 6000  ---  Trees 48000\n",
            "\n",
            "Train Corr: 0.2788\n",
            "Valid Corr: 0.0355\n",
            "\n",
            "Time: 182.44s  --  Step: 15.22s  --  TPS: 262.9\n",
            "\n",
            "\n",
            "\n",
            "Round: 6500  ---  Trees 52000\n",
            "\n",
            "Train Corr: 0.2889\n",
            "Valid Corr: 0.0356\n",
            "\n",
            "Time: 197.66s  --  Step: 15.22s  --  TPS: 262.8\n",
            "\n",
            "\n",
            "\n",
            "Round: 7000  ---  Trees 56000\n",
            "\n",
            "Train Corr: 0.2986\n",
            "Valid Corr: 0.0358\n",
            "\n",
            "Time: 212.90s  --  Step: 15.24s  --  TPS: 262.5\n",
            "\n",
            "\n",
            "\n",
            "Round: 7500  ---  Trees 60000\n",
            "\n",
            "Train Corr: 0.3080\n",
            "Valid Corr: 0.0358\n",
            "\n",
            "Time: 228.11s  --  Step: 15.21s  --  TPS: 263.0\n",
            "\n",
            "\n",
            "\n",
            "Round: 8000  ---  Trees 64000\n",
            "\n",
            "Train Corr: 0.3168\n",
            "Valid Corr: 0.0359\n",
            "\n",
            "Time: 243.32s  --  Step: 15.22s  --  TPS: 262.9\n",
            "\n",
            "\n",
            "\n",
            "Round: 8500  ---  Trees 68000\n",
            "\n",
            "Train Corr: 0.3253\n",
            "Valid Corr: 0.0359\n",
            "\n",
            "Time: 258.55s  --  Step: 15.22s  --  TPS: 262.8\n",
            "\n",
            "\n",
            "\n",
            "Round: 9000  ---  Trees 72000\n",
            "\n",
            "Train Corr: 0.3334\n",
            "Valid Corr: 0.0359\n",
            "\n",
            "Time: 273.83s  --  Step: 15.29s  --  TPS: 261.7\n",
            "\n",
            "\n",
            "\n",
            "Round: 9500  ---  Trees 76000\n",
            "\n",
            "Train Corr: 0.3412\n",
            "Valid Corr: 0.0359\n",
            "\n",
            "Time: 289.06s  --  Step: 15.23s  --  TPS: 262.6\n",
            "\n",
            "\n",
            "\n",
            "Round: 10000  ---  Trees 80000\n",
            "\n",
            "Train Corr: 0.3487\n",
            "Valid Corr: 0.0359\n",
            "\n",
            "Time: 304.28s  --  Step: 15.22s  --  TPS: 262.8\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.03592353],\n",
              "       [0.03592353, 1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "\n",
        "Xte = encode_cuts(Xt)\n",
        "Xve = encode_cuts(Xv)\n",
        "\n",
        "\n",
        "logger = LoggingCallback()\n",
        "\n",
        "\n",
        "booster = ExtraFastBooster( trees_per_layer=trees_per_layer, max_depth=max_depth, nfeatsets=nfeatsets, lr=lr, L2=L2, qgrad_bits=12 )\n",
        "\n",
        "booster.fit(Xte, Yt, Xve, Yv,  F,  FST, callbacks=[logger])\n",
        "\n",
        "booster.save('saved_booster.npz')\n",
        "\n",
        "\n",
        "pv = booster.predict(Xve, Yv.shape[0])\n",
        "\n",
        "\n",
        "np.corrcoef(pv, Yv)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Offline Model"
      ],
      "metadata": {
        "id": "TYxW0u7iEH2H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHO3cEYdtK-I"
      },
      "outputs": [],
      "source": [
        "@jit(nopython=True)\n",
        "def pack_cuts_32(X, n):\n",
        "\n",
        "  Xo = np.zeros( ( n*X.shape[0],  ( X.shape[1]+ 31 )>>5 )  , np.uint32)\n",
        "\n",
        "  for f in range( X.shape[0] ):\n",
        "    for k in range( X.shape[1] ):\n",
        "\n",
        "      x = X[f, k]\n",
        "\n",
        "      for s in range(n):\n",
        "\n",
        "        Xo[n*f + s, k>>5] |=  ( 1 << ( k&31 ) ) * ( x > s )\n",
        "\n",
        "\n",
        "  return Xo\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "@numba.jit(nopython=True)\n",
        "def _advance_and_predict_offline(X, P, I, V,  L_old, L_new, tree_set, max_depth):\n",
        "\n",
        "  for depth in range(max_depth):\n",
        "    for tree_fold in range(I.shape[1]):\n",
        "      for k in range(L_new.shape[-1]):\n",
        "\n",
        "        leaf = ( L_old[tree_fold, depth-1, k] if depth > 0 else 0 )\n",
        "\n",
        "        lo = leaf + (1<<depth) - 1\n",
        "\n",
        "        li = I[tree_set, tree_fold, lo]\n",
        "\n",
        "        x = ( X[li, k>>5] >> ( k&31  ) ) & 1\n",
        "\n",
        "        leaf =  2*leaf + x\n",
        "\n",
        "        if depth < L_new.shape[1]:\n",
        "          L_new[tree_fold, depth, k] = leaf\n",
        "\n",
        "\n",
        "        P[k] += V[tree_set, tree_fold, 2*lo + 1 + x ]\n",
        "\n",
        "  return\n",
        "\n",
        "\n",
        "def predict_offline(X, I, V, max_depth, n):\n",
        "  P = np.zeros((n,), np.int32)\n",
        "  L_old = np.zeros(( I.shape[1], max_depth-1, n), np.uint16)\n",
        "  L_new = np.zeros(( I.shape[1], max_depth-1, n), np.uint16)\n",
        "\n",
        "\n",
        "  for k in range(I.shape[0]):\n",
        "\n",
        "    _advance_and_predict_offline(X, P, I, V, L_old, L_new, k, min(k+1, max_depth))\n",
        "\n",
        "    L_new, L_old = L_old, L_new\n",
        "\n",
        "  return P\n",
        "\n",
        "\n",
        "class OfflineExtraFastBooster(object):\n",
        "\n",
        "\n",
        "  def __init__(self, path):\n",
        "    data = np.load(path)\n",
        "\n",
        "    self.V = data['V']\n",
        "    self.I = data['I']\n",
        "    self.max_depth = int.bit_count(self.I.shape[-1])\n",
        "\n",
        "\n",
        "  def predict(self, X, n=None):\n",
        "\n",
        "    n = 32*X.shape[1] if n is None else n\n",
        "\n",
        "    return predict_offline(X, self.I, self.V, self.max_depth, n)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Offline Prediction\n",
        "\n",
        "Verifying offlne preds for one era:\n"
      ],
      "metadata": {
        "id": "hcvXrkpShT02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "off = OfflineExtraFastBooster('saved_booster.npz')\n",
        "\n",
        "b = Ev==np.min(Ev)\n",
        "\n",
        "Xve = Xv[b].T\n",
        "\n",
        "Xve = pack_cuts_32(Xve, 4)\n",
        "\n",
        "pvo = off.predict(Xve, b.sum() )\n",
        "\n",
        "np.corrcoef(pvo, pv[b])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9tTnkV0EO4o",
        "outputId": "6d424b06-2152-47ff-8a96-7a8721305a78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1.],\n",
              "       [1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload Diagnostics"
      ],
      "metadata": {
        "id": "pfCujcjHmCim"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5EHQcWzQP-D"
      },
      "outputs": [],
      "source": [
        "pv = pv-np.min(pv)\n",
        "\n",
        "pv = pv/np.max(pv)\n",
        "\n",
        "pv = pv*.98+.01\n",
        "\n",
        "\n",
        "df_sub['prediction'] = pv[:df_sub.shape[0]]\n",
        "\n",
        "\n",
        "df_sub.to_csv('predictions.csv')\n",
        "submission_id = napi.upload_diagnostics(\"predictions.csv\", model_id=napi.get_models()[your_model_slot_name])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "r-xZlzUtk22u",
        "UljfsEI3lqCV",
        "FPjepAyskQDG",
        "VtHh0qXhAH_5",
        "S_3nKsZ5dqRt",
        "TYxW0u7iEH2H"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}